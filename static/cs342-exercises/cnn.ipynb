{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpQGxEVFl9vN"
   },
   "source": [
    "## Coding 4: CIFAR-10 with a Convolutional Neural Networks\n",
    "\n",
    "In this exercise, we will finish our CIFAR-10 adventures and do multi-class image classification task with a convolutional neural network (CNN).\n",
    "\n",
    "The data and setup for the model is identical to the previous coding assignment,\n",
    "but this time, we will explore the effects of several layers newly introduced in the lectures.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2510/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" width=1024px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi_aPuqRP4B5"
   },
   "source": [
    "### TensorBoard Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IztUb8tB_27X"
   },
   "source": [
    "We'll use TensorBoard to monitor training across runs. For classification tasks, we will mostly care about loss and accuracy.\n",
    "\n",
    "Make sure to run this only once - if TensorBoard fails to load, give it some time, and if nothing shows, you'll need to restart your runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8SCS2ZYwhS0"
   },
   "outputs": [],
   "source": [
    "import torch.utils.tensorboard as tb\n",
    "\n",
    "log_dir = 'log'\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir} --reload_interval 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtvv5znXPvas"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qOjsbCxif4d"
   },
   "source": [
    "Here is the same code from the previous exercise - This time, play around with the `transform`, and perform data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiJrDKTwl9vU"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "def fetch_dataloader(batch_size, transform=None, is_train=True):\n",
    "    \"\"\"\n",
    "    Loads data from disk and returns a data_loader.\n",
    "    A DataLoader is similar to a list of (image, label) tuples.\n",
    "    You do not need to fully understand this code to do this assignment, we're happy to explain though.\n",
    "    \"\"\"\n",
    "    data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Custom train/val split.\n",
    "    indices = [i for i in range(len(data)) if (i%10 > 0) == is_train]\n",
    "\n",
    "    data = torch.utils.data.Subset(data, indices)\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    return loader\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "data_train = fetch_dataloader(64, train_transform, is_train=True)\n",
    "data_val = fetch_dataloader(64, val_transform, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEezpyWB_V9P"
   },
   "source": [
    "## Model Implementation.\n",
    "\n",
    "Here we will implement a CNN. The following operations will be relevant -\n",
    "\n",
    "* `torch.nn.Conv2d` \n",
    "* `torch.nn.ReLU` \n",
    "* `torch.nn.AvgPool2d` \n",
    "* `torch.nn.MaxPool2d`\n",
    "\n",
    "Take a close look at the parameters of `Conv2d`. Play around with the following and see how it affects the output activation map.\n",
    "\n",
    "* kernel_size\n",
    "* stride\n",
    "* padding\n",
    "* dilation\n",
    "\n",
    "*Tensorboard*: So far we've only logged scalar feature. Let's spend a couple minutes today implementing logging images to tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBh5pFy8l9vj"
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        \"\"\"\n",
    "        Define the layer(s) needed for the model.\n",
    "        Feel free to define additional input arguments.\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        # A common starting point for Convolutional networks is:\n",
    "        # [Conv Layer, ReLU, (maybe MaxPool)] x N, then global AvePool, then Linear\n",
    "        # Play around with the number of convolutional layers, the number of channels,\n",
    "        # the kernel size, etc.\n",
    "        # TODO: Define the model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Calculate the classification score (logits).\n",
    "\n",
    "        Input: \n",
    "            x (float tensor N x 3 x 32 x 32): input images\n",
    "        Output:\n",
    "            y (float tensor N x 10): classification scores (logits) for each class\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, image):\n",
    "        return self(image).argmax(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rMr0NFgFJt_"
   },
   "source": [
    "## Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4fCGvlBXcFR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, data_train, data_val, device, lr=0.001, epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model. Feel free to add arguments for additional model tuning.\n",
    "\n",
    "    Input:\n",
    "      model (torch.nn.Module): the model to train\n",
    "      data_train (torch.utils.data.Dataloader): yields batches of data\n",
    "      data_val (torch.utils.data.Dataloader): use this to validate your model\n",
    "      device (torch.device): which device to use to perform computation\n",
    "\n",
    "      (optional) lr: learning rate hyperparameter\n",
    "      (optional) epochs: number of passes over dataloader\n",
    "    \"\"\"\n",
    "    # Setting up the tensorboard logger\n",
    "    logger = tb.SummaryWriter(log_dir + '/{}'.format(time.strftime('%H-%M-%S')))\n",
    "    global_step = 0\n",
    "\n",
    "    # Setup the loss function to use\n",
    "    loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Setup the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Wrap in a progress bar.\n",
    "    for epoch in range(epochs):\n",
    "        # Set the model to training mode.\n",
    "        model.train()\n",
    "\n",
    "        for x, y in data_train:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Forward pass through the network\n",
    "            output = model(x)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_function(output, y)\n",
    "            \n",
    "            # update model weights.\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add loss to TensorBoard.\n",
    "            logger.add_scalar('loss', loss, global_step=global_step)\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "        # Set the model to eval mode and compute accuracy.\n",
    "        # No need to change this, but feel free to implement additional logging.\n",
    "        model.eval()\n",
    "\n",
    "        accuracys_val = list()\n",
    "\n",
    "        for x, y in data_val:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model.predict(x)\n",
    "            accuracy_val = (y_pred == y).float().mean().item()\n",
    "            accuracys_val.append(accuracy_val)\n",
    "\n",
    "        accuracy = torch.FloatTensor(accuracys_val).mean().item()\n",
    "\n",
    "        logger.add_scalar('accuracy', accuracy, global_step=global_step)\n",
    "        grid = torchvision.utils.make_grid(0.5*x+0.5)\n",
    "        logger.add_image('images', grid, global_step=global_step)\n",
    "\n",
    "\n",
    "# Actually train the model here!\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNNClassifier(3, 10)\n",
    "model.to(device)\n",
    "\n",
    "train(model, data_train, data_val, device, lr=1e-3, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q03NWrdwl9vs"
   },
   "source": [
    "### References\n",
    "[CNN image taken from blog post](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
    "\n",
    "[PyTorch nn documentation](https://pytorch.org/docs/stable/nn.html)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ogwBlUCPPHb3"
   ],
   "name": "coding_05.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
