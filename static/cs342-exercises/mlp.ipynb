{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpQGxEVFl9vN"
   },
   "source": [
    "## Coding 4: CIFAR-10 with a Deep Network\n",
    "\n",
    "In this exercise, we will continue our CIFAR-10 adventures and tackle the multi-class image classification task with a deep network!  \n",
    "\n",
    "The data and setup for the model is almost identical to the previous coding assignment,  \n",
    "but this time, we will focus more on the model and data.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/1024px-Colored_neural_network.svg.png\" width=200px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IztUb8tB_27X"
   },
   "source": [
    "### TensorBoard Setup\n",
    "\n",
    "We'll use TensorBoard to monitor training across runs.  \n",
    "For classification tasks, we will mostly care about loss and accuracy.\n",
    "\n",
    "Make sure to run this only once - if TensorBoard fails to load,  \n",
    "give it some time, and if nothing shows, you'll need to restart your runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8SCS2ZYwhS0"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import torch.utils.tensorboard as tb\n",
    "\n",
    "log_dir = tempfile.mkdtemp()\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir} --reload_interval 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qOjsbCxif4d"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "Here is similar code from the previous exercise -  \n",
    "This cell will download the data and wrap it in a `torch.utils.Dataloader` object,  \n",
    "which does a lot of nice things like  \n",
    "* Batching\n",
    "* Shuffling\n",
    "* Parallel IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiJrDKTwl9vU"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "def fetch_dataloader(batch_size, transform=None, is_train=True):\n",
    "    \"\"\"\n",
    "    Loads data from disk and returns a data_loader.\n",
    "    A DataLoader is similar to a list of (image, label) tuples.\n",
    "    You do not need to fully understand this code to do this assignment, we're happy to explain though.\n",
    "    \"\"\"\n",
    "    data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Custom train/val split.\n",
    "    indices = [i for i in range(len(data)) if (i%10 > 0) == is_train]\n",
    "\n",
    "    data = torch.utils.data.Subset(data, indices)\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "      \n",
    "    return loader\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "data_train = fetch_dataloader(64, train_transform, is_train=True)\n",
    "data_val = fetch_dataloader(64, val_transform, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEezpyWB_V9P"
   },
   "source": [
    "## Model Implementation.\n",
    "\n",
    "Here we will implement a deep classifier.\n",
    "\n",
    "`torch.nn.Linear` will be useful, along with your favorite activation layer.\n",
    "\n",
    "* `torch.nn.Sigmoid`\n",
    "* `torch.nn.Tanh`\n",
    "* `torch.nn.ReLU`\n",
    "* `torch.nn.PReLU`\n",
    "* `torch.nn.*ReLU`\n",
    "\n",
    "See [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) for additional layers.\n",
    "\n",
    "If you're feeling brave, implement the activation layer on your own!  \n",
    "This includes the `forward` and `backward` functions.\n",
    "\n",
    "Once this is done, try to clean things up using `torch.nn.Sequential`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBh5pFy8l9vj"
   },
   "outputs": [],
   "source": [
    "class DeepClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Define the layer(s) needed for the model.\n",
    "        Feel free to define additional input arguments.\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        # TODO: Set up the model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Calculate the classification score (logits).\n",
    "\n",
    "        Input: \n",
    "            x (float tensor N x 3 x 32 x 32): input images\n",
    "        Output:\n",
    "            y (float tensor N x 10): classification scores (logits) for each class\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"\n",
    "        Predict the class label of the image.\n",
    "\n",
    "        Input:\n",
    "            image (float tensor N X 3 x 32 x 32): input images\n",
    "        Output:\n",
    "            label (long tensor N): the class labels in range [0, 9]\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NNKwqHP6ok8C"
   },
   "source": [
    "## Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNr2tNqHoc7_"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, data_train, data_val, device, lr=0.001, epochs=10):\n",
    "    \"\"\"\n",
    "    Train the model. Feel free to add arguments for additional model tuning.\n",
    "\n",
    "    Input:\n",
    "      model (torch.nn.Module): the model to train\n",
    "      data_train (torch.utils.data.Dataloader): yields batches of data\n",
    "      data_val (torch.utils.data.Dataloader): use this to validate your model\n",
    "      device (torch.device): which device to use to perform computation\n",
    "\n",
    "      (optional) lr: learning rate hyperparameter\n",
    "      (optional) epochs: number of passes over dataloader\n",
    "    \"\"\"\n",
    "    # Setting up the tensorboard logger\n",
    "    logger = tb.SummaryWriter(log_dir + '/{}'.format(time.strftime('%H-%M-%S')))\n",
    "    global_step = 0\n",
    "\n",
    "    # Setup the loss function to use\n",
    "    # TODO\n",
    "\n",
    "    # Setup the optimizer\n",
    "    # TODO\n",
    "\n",
    "    # Wrap in a progress bar.\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch:\", epoch)\n",
    "        \n",
    "        # Set the model to training mode.\n",
    "        model.train()\n",
    "\n",
    "        for x, y in data_train:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Do one training step\n",
    "            # TODO\n",
    "\n",
    "            # Add loss to TensorBoard.\n",
    "            logger.add_scalar('loss', loss, global_step=global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        # Set the model to eval mode and compute accuracy.\n",
    "        # No need to change this, but feel free to implement additional logging.\n",
    "        model.eval()\n",
    "\n",
    "        accuracys_val = list()\n",
    "\n",
    "        for x, y in data_val:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model.predict(x)\n",
    "            accuracy_val = (y_pred == y).float().mean().item()\n",
    "            accuracys_val.append(accuracy_val)\n",
    "\n",
    "        accuracy = torch.FloatTensor(accuracys_val).mean().item()\n",
    "\n",
    "        logger.add_scalar('accuracy', accuracy, global_step=global_step)\n",
    "\n",
    "\n",
    "# Actually train the model here!\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = DeepClassifier(3 * 32 * 32, 10)\n",
    "model.to(device)\n",
    "\n",
    "train(model, data_train, data_val, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q03NWrdwl9vs"
   },
   "source": [
    "### References\n",
    "[Linear Classifier Wikipedia article](https://en.wikipedia.org/wiki/Linear_classifier).\n",
    "\n",
    "[PyTorch nn documentation](https://pytorch.org/docs/stable/nn.html)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "coding_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
