{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUbWjm9pTqDY"
   },
   "source": [
    "# Coding 12: Imitation Learning++\n",
    "\n",
    "This week we will train a deep network that learns to race in SuperTuxKart using only the camera and speedometer.\n",
    "\n",
    "The network will take in an image and directly regress to low-level controls (steering, acceleration, brake, drift).\n",
    "\n",
    "<img src=\"https://a.fsdn.com/con/app/proj/supertuxkart/screenshots/500px-Hac.jpg/max/max/1\" width=512px/>\n",
    "\n",
    "We have already completed a basic implementation of this agent, this week we will improve it\n",
    "* through better data collection\n",
    "* Iterative training of better and better agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tq9eXWrmcVEk"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjYGw3YUU8G9"
   },
   "outputs": [],
   "source": [
    "!pip install PySuperTuxKart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtOE8RW5cot8"
   },
   "source": [
    "## The Environment\n",
    "\n",
    "The first part of the code is the same as last week's imitation learning exercise.\n",
    "No need to modify any of the code - just read over the `rollout` method to see how your agent is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjYGtvDuTqDZ"
   },
   "outputs": [],
   "source": [
    "import pystk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class PyTux(object):\n",
    "    INITED = False\n",
    "\n",
    "    def __init__(self, track, screen_width=128, screen_height=96):\n",
    "        self.race = None\n",
    "        self.config = pystk.GraphicsConfig.ld()\n",
    "        self.config.screen_width = screen_width\n",
    "        self.config.screen_height = screen_height\n",
    "        self.track = track\n",
    "\n",
    "        if not PyTux.INITED:\n",
    "            pystk.init(self.config)\n",
    "            PyTux.INITED = True\n",
    "\n",
    "    @staticmethod\n",
    "    def _magical_auto_pilot(player, track, distance=20):\n",
    "        \"\"\"\n",
    "        This function return a magical steering, acceleration and drift values.\n",
    "        This is used in the auto-pilot and meant to be hard to read ;)\n",
    "        Feel free to get inspired by this if you can decipher it\n",
    "        (it's probably not worth your time though)\n",
    "        \"\"\"\n",
    "        __ = PyTux._point_on_track(player.kart.distance_down_track+distance, track)\n",
    "        __ = __ - np.array(player.kart.location)\n",
    "        _ = np.array(player.kart.front) - np.array(player.kart.location)\n",
    "        _ = _ / max(np.linalg.norm(_), 1e-10)\n",
    "        _ = np.cross([0,1,0], _)\n",
    "        return lambda ___: (_.dot(__), int(___<15), abs(__.dot(_))>1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _point_on_track(distance, track):\n",
    "        node_idx = np.searchsorted(track.path_distance[..., 1], distance % track.path_distance[-1, 1]) % len(track.path_nodes)\n",
    "        d = track.path_distance[node_idx]\n",
    "        x = track.path_nodes[node_idx]\n",
    "        t = (distance - d[0]) / (d[1] - d[0])\n",
    "        return x[1] * t + x[0] * (1 - t)\n",
    "\n",
    "    def clean(self):\n",
    "        if self.race is not None:\n",
    "            self.race.stop()\n",
    "            del self.race\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.clean()\n",
    "\n",
    "        config = pystk.RaceConfig(num_kart=1, laps=1, track=self.track, step_size=0.1)\n",
    "        config.players[0].controller = pystk.PlayerConfig.Controller.PLAYER_CONTROL\n",
    "\n",
    "        self.race = pystk.Race(config)\n",
    "        self.race.start()\n",
    "        self.race.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.clean()\n",
    "\n",
    "    def rollout(self, agent, max_frames=1000):\n",
    "        \"\"\"\n",
    "        agent: an object that implements the act method\n",
    "        max_frames: maximum number of frames to play for\n",
    "\n",
    "        returns: tuple of (number steps, overall distance, did the agent finish)\n",
    "        \"\"\"\n",
    "        state = pystk.WorldState()\n",
    "        track = pystk.Track()\n",
    "\n",
    "        for t in range(max_frames):\n",
    "            state.update()\n",
    "            track.update()\n",
    "\n",
    "            player = state.players[0]\n",
    "\n",
    "            # Terminate if the kart finishes a lap.\n",
    "            if np.isclose(player.kart.overall_distance / track.length, 1.0, atol=2e-3):\n",
    "                return t, 200 - 100 * (t + 1) / max_frames, True\n",
    "\n",
    "            image = np.array(self.race.render_data[0].image)\n",
    "            auto_pilot = self._magical_auto_pilot(player, track)\n",
    "            speed = np.linalg.norm(player.kart.velocity)\n",
    "\n",
    "            self.race.step(agent.act(image, auto_pilot, speed))\n",
    "        return t, 100 * player.kart.overall_distance / track.length, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s31WSaY7TqDb"
   },
   "source": [
    "## The Agent\n",
    "\n",
    "This is very similar to what we saw last week, except that the `AgentWrapper` class now takes a `noise` parameter. You should use this noise to randomly modify the actions returned by the `act` method. Higher noise values should correspond to more randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDRPQRPgTqDc"
   },
   "outputs": [],
   "source": [
    "class AgentWrapper(object):\n",
    "    \"\"\"\n",
    "    Wraps any agent to collect extra information, used for\n",
    "    - collecting data\n",
    "    - visualizing runs\n",
    "    \"\"\"\n",
    "    ACTIONS = ['steer', 'acceleration', 'brake', 'drift']\n",
    "\n",
    "    def __init__(self, agent, noise=0):\n",
    "        self.agent = agent\n",
    "        self.noise = noise\n",
    "\n",
    "        self.images = list()\n",
    "        self.actions = list()\n",
    "\n",
    "    def act(self, image, auto_pilot, speed):\n",
    "        action = self.agent.act(image, auto_pilot, speed)\n",
    "        self.images.append(image.copy())\n",
    "        self.actions.append([getattr(action, x) for x in self.ACTIONS])\n",
    "\n",
    "        # Use self.noise to randomly change the returned action -- if noise = 0,\n",
    "        # then you should return the action unchanged, and the random deviation\n",
    "        # should increase as noise increases.\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "        Call on the last line of a cell to visualize the most recent run.\n",
    "        \"\"\"\n",
    "        from moviepy.editor import ImageSequenceClip\n",
    "        from IPython.display import display\n",
    "\n",
    "        display(ImageSequenceClip(self.images, fps=15).ipython_display(width=512, autoplay=True, loop=True))\n",
    "\n",
    "\n",
    "class Autopilot(object):\n",
    "    last_drift = False\n",
    "    def act(self, image, auto_pilot, speed):\n",
    "        \"\"\"\n",
    "        Implement your autopilot here.\n",
    "        \"\"\"\n",
    "        action = pystk.Action()\n",
    "        # Let's use a magical auto-pilot function to get the correct actions\n",
    "        steer, acceleration, drift = auto_pilot(speed)\n",
    "        # Let's make sure the auto-pilot's actions fall within our limits\n",
    "        action.steer = np.clip(steer, -1, 1)\n",
    "        action.acceleration = np.clip(acceleration,0,1)\n",
    "        # Cheap trick, never drift twice in a row (you'll slide out of control)\n",
    "        action.drift = int(drift) and not self.last_drift\n",
    "        self.last_drift = action.drift\n",
    "        action.brake = 0\n",
    "        return action\n",
    "\n",
    "\n",
    "TRACK = 'lighthouse'\n",
    "TRACK_TIME = 700\n",
    "\n",
    "# Test out your controller!\n",
    "agent = AgentWrapper(Autopilot(), noise=1)\n",
    "\n",
    "with PyTux(TRACK) as env:\n",
    "    print('Time: %d Distance: %d Success: %d' % env.rollout(agent, TRACK_TIME))\n",
    "\n",
    "agent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgdkby3GTqDe"
   },
   "source": [
    "## Data Collection\n",
    "\n",
    "Once again, our data collection looks pretty much the same as last week.\n",
    "\n",
    "For every frame we have the following data\n",
    "* image\n",
    "* action\n",
    "\n",
    "All we have to do is let the autopilot drive a couple times,  \n",
    "and we'll save this information from every frame.\n",
    "\n",
    "You should choose a number of episodes to collect data from (`N_EPISODES`) as well as a noise value to use in each episode. Note that it might be useful to use different noise values in different episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAvuUe52hXsG"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "DATASET_PATH = Path('drive_data')\n",
    "N_EPISODES = 20\n",
    "\n",
    "# Remove old data.\n",
    "!rm -rf $DATASET_PATH\n",
    "\n",
    "DATASET_PATH.mkdir()\n",
    "\n",
    "for episode in range(N_EPISODES):\n",
    "    # Change the noise value here. You might find it helpful to use different\n",
    "    # noise values for different episodes.\n",
    "    agent = AgentWrapper(Autopilot(), noise=0.25)\n",
    "\n",
    "    # Run one rollout.\n",
    "    with PyTux(TRACK) as env:\n",
    "        env.rollout(agent, TRACK_TIME)\n",
    "\n",
    "    # Save the data.\n",
    "    episode_dir = Path(DATASET_PATH) / ('%03d' % episode)\n",
    "    episode_dir.mkdir()\n",
    "\n",
    "    for i, (image, action) in enumerate(zip(agent.images, agent.actions)):\n",
    "        Image.fromarray(image).save(episode_dir / ('%05d.png' % i))\n",
    "        np.savetxt(episode_dir / ('%05d.csv' % i), action, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIctTXWxgvDy"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Now that the data is collected, we'll load it using our standard SuperTuxDataset (from HW1-3).\n",
    "\n",
    "No need to change anything here, just take a look at the `visualize_sample` code as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4gwdYdDTqDe"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pathlib\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "class SuperTuxDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, episode_dir, transform=torchvision.transforms.ToTensor()):\n",
    "        episode_dir = pathlib.Path(episode_dir)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.image_paths = list((episode_dir).glob('*.png'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        image = self.transform(image)\n",
    "\n",
    "        action = np.loadtxt(str(self.image_paths[idx]).replace('.png', '.csv'), delimiter=',')\n",
    "        action = torch.FloatTensor(action)\n",
    "\n",
    "        return image, action\n",
    "\n",
    "\n",
    "def load_data(dataset_path, batch_size=128, transform=torchvision.transforms.ToTensor()):\n",
    "    dataset = list()\n",
    "\n",
    "    for episode_dir in pathlib.Path(dataset_path).glob('*'):\n",
    "        data = SuperTuxDataset(episode_dir, transform)\n",
    "        dataset.append(data)\n",
    "\n",
    "    dataset = torch.utils.data.ConcatDataset(dataset)\n",
    "\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_sample(image, action):\n",
    "    image = (255 * image).byte().numpy().transpose(1, 2, 0)\n",
    "    image = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for i, a in enumerate(action):\n",
    "        draw.text((5, 5 + 15 * i), str(a.item()), fill=(255, 0, 0))\n",
    "\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "n_samples = 4\n",
    "fig, axes = plt.subplots(1, n_samples)\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "data = SuperTuxDataset(DATASET_PATH / '000')\n",
    "\n",
    "for i in range(n_samples):\n",
    "    idx = np.random.randint(len(data))\n",
    "    axes[i].imshow(visualize_sample(*data[idx]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtmPfxGKXe1g"
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsf0SfLTXkXh"
   },
   "outputs": [],
   "source": [
    "import torch.utils.tensorboard as tb\n",
    "\n",
    "log_dir = 'dagger_log'\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir} --reload_interval 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhRDCQu4TqDg"
   },
   "source": [
    "## Model + Training\n",
    "\n",
    "Now we can finally define our model. The provided model architecture is sufficient to complete a lap, but you may change it if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkOGoUbXTqDg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# You may change this model architecture if you like. I was able to complete a\n",
    "# lap with this architecture, so you don't have to change it if you prefer not\n",
    "# to.\n",
    "class CNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, c_in=3, c_out=2):\n",
    "        super().__init__()\n",
    "        self.norm = torch.nn.BatchNorm2d(c_in)\n",
    "        self.network = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(c_in, 32, 5, stride=2, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, 5, stride=2, padding=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 128, 5, stride=2, padding=2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.classifier = torch.nn.Linear(128, c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        x = self.network(x)\n",
    "        x = x.mean((2, 3))\n",
    "\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def act(self, image, _, speed):\n",
    "        \"\"\"\n",
    "        Implement this.\n",
    "\n",
    "        Remember that image comes in as a np.uint8 array, with shape (h, w, 3).\n",
    "        The values range from [0-255]\n",
    "        \"\"\"\n",
    "        image = torchvision.transforms.ToTensor()(image)[None]\n",
    "        pred = self(image)[0]\n",
    "        action = pystk.Action()\n",
    "        action.steer = pred[0]\n",
    "        action.acceleration = pred[1]\n",
    "        action.drift = 0\n",
    "        action.brake = 0\n",
    "        return action\n",
    "\n",
    "\n",
    "def train(model, device, lr=0.001, epochs=20):\n",
    "    logger = tb.SummaryWriter(log_dir + '/{}'.format(time.strftime('%H-%M-%S')), flush_secs=1)\n",
    "\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    global_step = 0\n",
    "\n",
    "    loss_func = torch.nn.SmoothL1Loss()\n",
    "    \n",
    "    model.to(device)\n",
    "\n",
    "    image = None\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        \n",
    "        for image_c, action_c in data_train:\n",
    "            image, action = image_c.to(device), action_c.to(device)\n",
    "            pred_steer = model(image)\n",
    "            \n",
    "            loss = loss_func(pred_steer[..., :2], action[..., :2])\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            logger.add_scalar('loss/train', loss.item(), global_step)\n",
    "            global_step += 1\n",
    "\n",
    "            # Add image visualization.\n",
    "            # visualize_sample(image, action)\n",
    "\n",
    "\n",
    "# Train your model.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_train = load_data('drive_data', batch_size=16)\n",
    "\n",
    "model = CNNClassifier()\n",
    "model.to(device)\n",
    "\n",
    "train(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scroll down to the bottom of the notebook for the visualization code you can use to see how your agent performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cG1UHsZ3xiJM"
   },
   "source": [
    "# DAgger\n",
    "\n",
    "Now we'll look at solving the same problem with DAgger. How should you implement `act` in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8t61KG3NxgwQ"
   },
   "outputs": [],
   "source": [
    "class DaggerAgentWrapper(object):\n",
    "    \"\"\"\n",
    "    Wraps any agent to collect extra information, used for\n",
    "    - collecting data\n",
    "    - visualizing runs\n",
    "    \"\"\"\n",
    "    ACTIONS = ['steer', 'acceleration', 'brake', 'drift']\n",
    "\n",
    "    def __init__(self, autopilot_agent, agent, noise=0):\n",
    "        self.autopilot_agent = autopilot_agent\n",
    "        self.agent = agent\n",
    "        self.noise = noise\n",
    "        self._rescue = 0\n",
    "\n",
    "        self.images = list()\n",
    "        self.actions = list()\n",
    "\n",
    "    def act(self, image, auto_pilot, speed):\n",
    "        action = self.autopilot_agent.act(image, auto_pilot, speed)\n",
    "        self.images.append(image.copy())\n",
    "        self.actions.append([getattr(action, x) for x in self.ACTIONS])\n",
    "\n",
    "        # This is not the correct implementation for DAgger\n",
    "\n",
    "        return action\n",
    "\n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "        Call on the last line of a cell to visualize the most recent run.\n",
    "        \"\"\"\n",
    "        from moviepy.editor import ImageSequenceClip\n",
    "        from IPython.display import display\n",
    "\n",
    "        display(ImageSequenceClip(self.images, fps=15).ipython_display(width=512, autoplay=True, loop=True))\n",
    "\n",
    "\n",
    "# Test out your controller!\n",
    "dagger_agent = DaggerAgentWrapper(Autopilot(), model, noise=1)\n",
    "\n",
    "with PyTux(TRACK) as env:\n",
    "    print('Time: %d Distance: %d Success: %d' % env.rollout(dagger_agent, TRACK_TIME))\n",
    "\n",
    "dagger_agent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jvl_zGzN0UiB"
   },
   "outputs": [],
   "source": [
    "N_DAGGER_EPISODES = 1\n",
    "for _ in range(N_DAGGER_EPISODES):\n",
    "    # Reset the agent.\n",
    "    dagger_agent = DaggerAgentWrapper(Autopilot(), model, noise=0.8)\n",
    "\n",
    "    # Run one rollout.\n",
    "    with PyTux(TRACK) as env:\n",
    "        env.rollout(dagger_agent, TRACK_TIME)\n",
    "\n",
    "    # Save the data.\n",
    "    episode += 1\n",
    "    episode_dir = Path(DATASET_PATH) / ('%03d' % episode)\n",
    "    episode_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for i, (image, action) in enumerate(zip(dagger_agent.images, dagger_agent.actions)):\n",
    "        Image.fromarray(image).save(episode_dir / ('%05d.png' % i))\n",
    "        np.savetxt(episode_dir / ('%05d.csv' % i), action, delimiter=',')\n",
    "\n",
    "data_train = load_data('drive_data', batch_size=16)\n",
    "train(model, device, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7uo3IVygfeU"
   },
   "source": [
    "## Fully Autonomous Driving\n",
    "\n",
    "Now that all that has been taken care of, it's time to finally test out your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJ9s-6RhTqDk"
   },
   "outputs": [],
   "source": [
    "# Is this necessary?\n",
    "model = model.cpu()\n",
    "#model.GAIN=1.2\n",
    "#model.ACCEL_GAIN=1\n",
    "\n",
    "# Test out your model!\n",
    "with PyTux(TRACK) as env:\n",
    "    agent = AgentWrapper(model)\n",
    "    print('Time: %d Distance Completed Percentage: %f Success: %d' % env.rollout(agent, TRACK_TIME))\n",
    "\n",
    "agent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M87JF8ztxOHb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Coding_12.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
