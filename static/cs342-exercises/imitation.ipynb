{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUbWjm9pTqDY"
   },
   "source": [
    "# Coding 11: Imitation Learning\n",
    "\n",
    "This week we will train a deep network that learns to race in SuperTuxKart using only the camera and speedometer.\n",
    "\n",
    "The network will take in an image and directly regress to low-level controls (steering, acceleration, brake, drift).\n",
    "\n",
    "<img src=\"https://a.fsdn.com/con/app/proj/supertuxkart/screenshots/500px-Hac.jpg/max/max/1\" width=512px/>\n",
    "\n",
    "This coding exercise consists of three main parts -\n",
    "\n",
    "* collecting data\n",
    "* training your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtOE8RW5cot8",
    "tags": []
   },
   "source": [
    "## The Environment\n",
    "\n",
    "The following code wraps the `pystk` library and provides a basic interface for playing the game.  \n",
    "No need to modify any of the code - just read over the `rollout` method to see how your agent is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjYGtvDuTqDZ"
   },
   "outputs": [],
   "source": [
    "import pystk\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "class PyTux(object):\n",
    "    INITED = False\n",
    "\n",
    "    def __init__(self, track, screen_width=128, screen_height=96):\n",
    "        self.race = None\n",
    "        self.config = pystk.GraphicsConfig.ld()\n",
    "        self.config.screen_width = screen_width\n",
    "        self.config.screen_height = screen_height\n",
    "        self.track = track\n",
    "\n",
    "        if not PyTux.INITED:\n",
    "            pystk.init(self.config)\n",
    "            PyTux.INITED = True\n",
    "\n",
    "    @staticmethod\n",
    "    def _magical_auto_pilot(player, track, distance=10):\n",
    "        \"\"\"\n",
    "        This function return a magical steering, acceleration and drift values.\n",
    "        This is used in the auto-pilot and meant to be hard to read ;)\n",
    "        Feel free to get inspired by this if you can decipher it\n",
    "        (it's probably not worth your time though)\n",
    "        \"\"\"\n",
    "        __ = PyTux._point_on_track(player.kart.distance_down_track+distance, track)\n",
    "        __ = __ - np.array(player.kart.location)\n",
    "        _ = np.array(player.kart.front) - np.array(player.kart.location)\n",
    "        _ = _ / max(np.linalg.norm(_), 1e-10)\n",
    "        _ = np.cross([0,1,0], _)\n",
    "        return lambda ___: (_.dot(__), int(___<15), abs(__.dot(_))>1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _point_on_track(distance, track):\n",
    "        node_idx = np.searchsorted(track.path_distance[..., 1], distance % track.path_distance[-1, 1]) % len(track.path_nodes)\n",
    "        d = track.path_distance[node_idx]\n",
    "        x = track.path_nodes[node_idx]\n",
    "        t = (distance - d[0]) / (d[1] - d[0])\n",
    "        return x[1] * t + x[0] * (1 - t)\n",
    "\n",
    "    def clean(self):\n",
    "        if self.race is not None:\n",
    "            self.race.stop()\n",
    "            del self.race\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.clean()\n",
    "\n",
    "        config = pystk.RaceConfig(num_kart=1, laps=1, track=self.track, step_size=0.1)\n",
    "        config.players[0].controller = pystk.PlayerConfig.Controller.PLAYER_CONTROL\n",
    "\n",
    "        self.race = pystk.Race(config)\n",
    "        self.race.start()\n",
    "        self.race.step()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.clean()\n",
    "        pystk.clean()\n",
    "        PyTux.INITED = False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def rollout(self, agent, max_frames=1000):\n",
    "        \"\"\"\n",
    "        agent: an object that implements the act method\n",
    "        max_frames: maximum number of frames to play for\n",
    "\n",
    "        returns: tuple of (number steps, overall distance, did the agent finish)\n",
    "        \"\"\"\n",
    "        state = pystk.WorldState()\n",
    "        track = pystk.Track()\n",
    "\n",
    "        for t in tqdm(range(max_frames)):\n",
    "            state.update()\n",
    "            track.update()\n",
    "\n",
    "            player = state.players[0]\n",
    "\n",
    "            # Terminate if the kart finishes a lap.\n",
    "            if np.isclose(player.kart.overall_distance / track.length, 1.0, atol=2e-3):\n",
    "                return t, player.kart.overall_distance, True\n",
    "\n",
    "            image = np.array(self.race.render_data[0].image)\n",
    "            auto_pilot = self._magical_auto_pilot(player, track)\n",
    "            speed = np.linalg.norm(player.kart.velocity)\n",
    "\n",
    "            self.race.step(agent.act(image, auto_pilot, speed))\n",
    "        return t, 100 * player.kart.overall_distance / track.length, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s31WSaY7TqDb",
    "tags": []
   },
   "source": [
    "## The Agent\n",
    "\n",
    "Here we'll implement our first agent - the autopilot.  \n",
    "All we need to do for the autopilot is implement the `act` method.  \n",
    "\n",
    "This method uses the `target` waypoint to compute an action, which consists of steering, acceleration, brake, and drift.\n",
    "\n",
    "**QUESTION:** what coordinates is `target` in?\n",
    "\n",
    "Aside: the autopilot gets *ground truth information* and is allowed to know the `target` every time step.  \n",
    "Isn't this cheating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDRPQRPgTqDc"
   },
   "outputs": [],
   "source": [
    "class AgentWrapper(object):\n",
    "    \"\"\"\n",
    "    Wraps any agent to collect extra information, used for\n",
    "    - collecting data\n",
    "    - visualizing runs\n",
    "    \"\"\"\n",
    "    ACTIONS = ['steer', 'acceleration', 'brake', 'drift']\n",
    "\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "\n",
    "        self.images = list()\n",
    "        self.actions = list()\n",
    "\n",
    "    def act(self, image, target, speed):\n",
    "        action = self.agent.act(image, target, speed)\n",
    "\n",
    "        self.images.append(image.copy())\n",
    "        self.actions.append([getattr(action, x) for x in self.ACTIONS])\n",
    "\n",
    "        return action\n",
    "\n",
    "    def show(self):\n",
    "        \"\"\"\n",
    "        Call on the last line of a cell to visualize the most recent run.\n",
    "        \"\"\"\n",
    "        from moviepy.editor import ImageSequenceClip\n",
    "        from IPython.display import display\n",
    "\n",
    "        display(ImageSequenceClip(self.images, fps=15).ipython_display(width=512, autoplay=True, loop=True))\n",
    "        \n",
    "        \n",
    "class Autopilot(object):\n",
    "    last_drift = False\n",
    "    def act(self, image, auto_pilot, speed):\n",
    "        action = pystk.Action()\n",
    "        # Let's use a magical auto-pilot function to get the correct actions\n",
    "        steer, acceleration, drift = auto_pilot(speed)\n",
    "        # Let's make sure the auto-pilot's actions fall within our limits\n",
    "        action.steer = np.clip(steer, -1, 1)\n",
    "        action.acceleration = np.clip(acceleration,0,1)\n",
    "        # Cheap trick, never drift twice in a row (you'll slide out of control)\n",
    "        action.drift = int(drift) and not self.last_drift\n",
    "        self.last_drift = action.drift\n",
    "        action.brake = 0\n",
    "        return action\n",
    "\n",
    "\n",
    "TRACK = 'lighthouse'\n",
    "TRACK_TIME = 700\n",
    "\n",
    "# Test out your controller!\n",
    "agent = AgentWrapper(Autopilot())\n",
    "\n",
    "with PyTux(TRACK) as env:\n",
    "    print('Time: %d Distance: %d Success: %d' % env.rollout(agent, TRACK_TIME))\n",
    "\n",
    "agent.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgdkby3GTqDe"
   },
   "source": [
    "## Data Collection\n",
    "\n",
    "Now that we have a decent autopilot, let's collect some data.  \n",
    "\n",
    "For every frame we have the following data\n",
    "* image\n",
    "* action\n",
    "\n",
    "All we have to do is let the autopilot drive a couple times,  \n",
    "and we'll save this information from every frame.\n",
    "\n",
    "No need to modify anything here besides `N_EPISODES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAvuUe52hXsG"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "DATASET_PATH = Path('drive_data')\n",
    "N_EPISODES = 1\n",
    "\n",
    "# Remove old data.\n",
    "!rm -rf $DATASET_PATH\n",
    "\n",
    "DATASET_PATH.mkdir()\n",
    "\n",
    "for episode in tqdm(range(N_EPISODES)):\n",
    "    # Reset the agent.\n",
    "    agent = AgentWrapper(Autopilot())\n",
    "\n",
    "    # Run one rollout.\n",
    "    with PyTux(TRACK) as env:\n",
    "        env.rollout(agent, TRACK_TIME)\n",
    "\n",
    "    # Save the data.\n",
    "    episode_dir = Path(DATASET_PATH) / ('%03d' % episode)\n",
    "    episode_dir.mkdir()\n",
    "\n",
    "    image_dir = episode_dir / 'images'\n",
    "    image_dir.mkdir()\n",
    "\n",
    "    for i, image in enumerate(agent.images):\n",
    "        Image.fromarray(image).save(image_dir / ('%05d.png' % i))\n",
    "\n",
    "    (episode_dir / 'actions.txt').write_text('\\n'.join(map(str, agent.actions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIctTXWxgvDy"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "Now that the data is collected, we'll load it using our standard SuperTuxDataset (from HW1-3).\n",
    "\n",
    "No need to change anything here, just take a look at the `visualize_sample` code as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4gwdYdDTqDe"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pathlib\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "class SuperTuxDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, episode_dir, transform=torchvision.transforms.ToTensor()):\n",
    "        episode_dir = pathlib.Path(episode_dir)\n",
    "\n",
    "        self.transform = transform\n",
    "        self.image_paths = list(sorted((episode_dir / 'images').glob('*.png')))\n",
    "        self.actions = list()\n",
    "\n",
    "        for line in (episode_dir / 'actions.txt').read_text().split('\\n'):\n",
    "            self.actions.append(eval(line))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx])\n",
    "        image = self.transform(image)\n",
    "\n",
    "        action = torch.FloatTensor(self.actions[idx])\n",
    "\n",
    "        return image, action\n",
    "\n",
    "\n",
    "def load_data(dataset_path, batch_size=128, transform=torchvision.transforms.ToTensor()):\n",
    "    dataset = list()\n",
    "\n",
    "    for episode_dir in pathlib.Path(dataset_path).glob('*'):\n",
    "        data = SuperTuxDataset(episode_dir, transform)\n",
    "        dataset.append(data)\n",
    "\n",
    "    dataset = torch.utils.data.ConcatDataset(dataset)\n",
    "\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_sample(image, action):\n",
    "    image = (255 * image).byte().numpy().transpose(1, 2, 0)\n",
    "    image = Image.fromarray(image)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    for i, a in enumerate(action):\n",
    "        draw.text((5, 5 + 15 * i), str(a.item()), fill=(255, 0, 0))\n",
    "\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "n_samples = 4\n",
    "fig, axes = plt.subplots(1, n_samples)\n",
    "fig.set_size_inches(20, 10)\n",
    "\n",
    "data = SuperTuxDataset(DATASET_PATH / '000')\n",
    "\n",
    "for i in range(n_samples):\n",
    "    idx = np.random.randint(len(data))\n",
    "    axes[i].imshow(visualize_sample(*data[idx]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtmPfxGKXe1g"
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsf0SfLTXkXh"
   },
   "outputs": [],
   "source": [
    "import torch.utils.tensorboard as tb\n",
    "\n",
    "log_dir = 'log'\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir} --reload_interval 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhRDCQu4TqDg"
   },
   "source": [
    "## Model + Training\n",
    "\n",
    "Now we can finally define our model.  \n",
    "The model takes in an image and outputs an action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkOGoUbXTqDg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "class CNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        # TODO: Implement this -- Your network does not need to be as big as other networks\n",
    "        # we've looked at in this class\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def act(self, image, _, speed):\n",
    "        \"\"\"\n",
    "        Implement this.\n",
    "\n",
    "        Remember that image comes in as a np.uint8 array, with shape (h, w, 3).\n",
    "        The values range from [0-255]\n",
    "        \"\"\"\n",
    "        action = pystk.Action()\n",
    "        # Use your network to set the following:\n",
    "        #action.steer, float between -1 and 1 -- the direction to steer\n",
    "        #action.acceleration, float between 0 and 1 -- the amount to accelerate\n",
    "        #action.drift, bool -- whether or not to drift, which can help with tight turns\n",
    "        #action.brake, bool -- whether or not to brake\n",
    "        return action\n",
    "\n",
    "\n",
    "def train(model, device, lr=0.001, epochs=1000):\n",
    "    logger = tb.SummaryWriter(log_dir + '/{}'.format(time.strftime('%H-%M-%S')), flush_secs=1)\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-6)\n",
    "    global_step = 0\n",
    "\n",
    "    # Is this the right loss?\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        model.train()\n",
    "        \n",
    "        for image, action in data_train:\n",
    "            image, action = image.to(device), action.to(device)\n",
    "            pred = model(image)\n",
    "            \n",
    "            # NOTE: The following loss function ignores the drift and brake outputs\n",
    "            # of your network. This can get you a pretty good controller and is a bit\n",
    "            # easier to train.\n",
    "            loss = loss_func(pred[..., :2], action[..., :2])\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            logger.add_scalar('loss/train', loss.item(), global_step)\n",
    "            global_step += 1\n",
    "\n",
    "            # Add image visualization.\n",
    "            # visualize_sample(image, action)\n",
    "\n",
    "\n",
    "# Train your model.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data_train = load_data('drive_data', batch_size=32)\n",
    "\n",
    "model = CNNClassifier(3, 4)\n",
    "model.to(device)\n",
    "\n",
    "train(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7uo3IVygfeU"
   },
   "source": [
    "## Fully Autonomous Driving\n",
    "\n",
    "Now that all that has been taken care of, it's time to finally test out your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJ9s-6RhTqDk"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.cpu()\n",
    "model.GAIN=1.2\n",
    "model.ACCEL_GAIN=100\n",
    "\n",
    "# Test out your model!\n",
    "with PyTux(TRACK) as env:\n",
    "    agent = AgentWrapper(model)\n",
    "    print('Time: %d Distance Completed Percentage: %f Success: %d' % env.rollout(agent, TRACK_TIME))\n",
    "\n",
    "agent.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhlKcfYCr7Lx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of coding_11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
