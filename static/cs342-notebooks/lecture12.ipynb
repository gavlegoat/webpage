{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e144e-b340-49dd-822e-326abb5c9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print('device = ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60280de3-7e52-4cfa-a8e2-eca46ebe0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same data loading code from our in-class exercises\n",
    "def fetch_dataloader(batch_size, transform=None, is_train=True):\n",
    "    data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    indices = [i for i in range(len(data)) if (i%10 > 0) == is_train]\n",
    "\n",
    "    data = torch.utils.data.Subset(data, indices)\n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603f8e95-c9fc-42cd-bc1e-0310e4e73d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we simply load the images without normalization\n",
    "train_transform = transforms.ToTensor()\n",
    "data_train = fetch_dataloader(64, train_transform, is_train=True)\n",
    "\n",
    "# Now compute image statistics. Since this takes a bit of time to run, what\n",
    "# I would do is just run this once then hardcode the output into the transform\n",
    "# for future calls.\n",
    "sums = torch.zeros(3)\n",
    "sq_sums = torch.zeros(3)\n",
    "batches = 0\n",
    "for data, _ in data_train:\n",
    "    sums += data.mean(dim=(0, 2, 3))\n",
    "    sq_sums += (data**2).mean(dim=(0, 2, 3))\n",
    "    batches += 1\n",
    "\n",
    "mean = sums / batches\n",
    "# Std[X] = sqrt(E[X^2] - E[X]^2)\n",
    "std = (sq_sums / batches - mean**2)**0.5\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c140bb-75f7-44e1-8d25-33f5dfa1a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I put the results into a normalize call. Every time I want to run this\n",
    "# code from now on, I would use this cell instead of the previous one.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4916, 0.4824, 0.4468), (0.2471, 0.2436, 0.2618))\n",
    "])\n",
    "data_train = fetch_dataloader(64, train_transform, is_train=True)\n",
    "data_valid = fetch_dataloader(64, train_transform, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8dc1f-4919-45e5-9ab4-961b81bc0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's look at Batch Normalization within the network.\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    class Block(torch.nn.Module):\n",
    "        def __init__(self, n_input, n_output, stride=1):\n",
    "            super().__init__()\n",
    "            self.net = torch.nn.Sequential(\n",
    "                # In this notebook I've put the normalizations before the convolutional layers. If\n",
    "                # you want to do them afterward, comment the line below and uncomment the later\n",
    "                # BatchNorm2d layer. In this case you will also want to set bias=False in the Conv2d\n",
    "                # constructor.\n",
    "                torch.nn.BatchNorm2d(n_input, affine=False),\n",
    "                torch.nn.Conv2d(n_input, n_output, kernel_size=3, padding=1, stride=stride),\n",
    "                #torch.nn.BatchNorm2d(n_output),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.BatchNorm2d(n_output, affine=False),\n",
    "                torch.nn.Conv2d(n_output, n_output, kernel_size=3, padding=1),\n",
    "                #torch.nn.BatchNorm2d(n_output),\n",
    "                torch.nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.net(x)\n",
    "        \n",
    "    def __init__(self, layers=[32,64,128], n_input_channels=3):\n",
    "        super().__init__()\n",
    "        L = [torch.nn.Conv2d(n_input_channels, 32, kernel_size=7, padding=3, stride=2),\n",
    "             # If you want to do BatchNorm after the convolutional layers, then you should add\n",
    "             # one here too. Remember to set bias=False in the convolution above.\n",
    "             #torch.nn.BatchNorm2d(32),\n",
    "             torch.nn.ReLU(),\n",
    "             torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "            ]\n",
    "        c = 32\n",
    "        for l in layers:\n",
    "            L.append(self.Block(c, l, stride=2))\n",
    "            c = l\n",
    "        self.network = torch.nn.Sequential(*L)\n",
    "        self.classifier = torch.nn.Linear(c, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Compute the features\n",
    "        z = self.network(x)\n",
    "        # Global average pooling\n",
    "        z = z.mean(dim=[2,3])\n",
    "        # Classify\n",
    "        return self.classifier(z)[:,0]\n",
    "    \n",
    "net = ConvNet()\n",
    "# When using BatchNorm, it is important to set the network to training mode and\n",
    "# evaluation mode. BatchNorm behaves differently depending on whether it is being\n",
    "# trained or tested.\n",
    "net.train()\n",
    "print(net.training)\n",
    "net.eval()\n",
    "print(net.training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a86ff3-dcf1-446e-a67f-9f734164996d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
